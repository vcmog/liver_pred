{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils.colonflag.feature_generation as fg\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import utils.missing_data as md\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, average_precision_score, f1_score, classification_report, precision_score, recall_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "#from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = r\"C:\\Users\\victo\\OneDrive - University of Leeds\\Documents\\Uni Work\\Project\\MIMIC Work\\Liver Cancer Prediction\\liver_pred\\data\\interim\"\n",
    "#processed_labs = pd.read_csv(dir + r\"\\processed_lab_data.csv\", parse_dates=[\"charttime\", \"index_date\"], index_col=0)\n",
    "cohort_ids = pd.read_csv(dir + r\"\\matched_cohort_ids.csv\", index_col=0)\n",
    "processed_labs = pd.read_csv(dir + r\"\\processed_lab_data.csv\", parse_dates=[\"charttime\", \"index_date\"], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>index_admission</th>\n",
       "      <th>test_admission</th>\n",
       "      <th>itemid</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>valueuom</th>\n",
       "      <th>flag</th>\n",
       "      <th>charttime</th>\n",
       "      <th>outcome</th>\n",
       "      <th>index_date</th>\n",
       "      <th>label</th>\n",
       "      <th>fluid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000980</td>\n",
       "      <td>25242409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50861</td>\n",
       "      <td>31.0</td>\n",
       "      <td>IU/L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2185-09-17 12:10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2191-04-03 18:48:00</td>\n",
       "      <td>Blood Alanine Aminotransferase (ALT)</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000980</td>\n",
       "      <td>25242409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50868</td>\n",
       "      <td>13.0</td>\n",
       "      <td>mEq/L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2185-09-17 12:10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2191-04-03 18:48:00</td>\n",
       "      <td>Blood Anion Gap</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000980</td>\n",
       "      <td>25242409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50878</td>\n",
       "      <td>32.0</td>\n",
       "      <td>IU/L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2185-09-17 12:10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2191-04-03 18:48:00</td>\n",
       "      <td>Blood Asparate Aminotransferase (AST)</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000980</td>\n",
       "      <td>25242409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50882</td>\n",
       "      <td>24.0</td>\n",
       "      <td>mEq/L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2185-09-17 12:10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2191-04-03 18:48:00</td>\n",
       "      <td>Blood Bicarbonate</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000980</td>\n",
       "      <td>25242409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50902</td>\n",
       "      <td>110.0</td>\n",
       "      <td>mEq/L</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>2185-09-17 12:10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2191-04-03 18:48:00</td>\n",
       "      <td>Blood Chloride</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  index_admission  test_admission  itemid  valuenum valueuom  \\\n",
       "0    10000980         25242409             NaN   50861      31.0     IU/L   \n",
       "1    10000980         25242409             NaN   50868      13.0    mEq/L   \n",
       "2    10000980         25242409             NaN   50878      32.0     IU/L   \n",
       "3    10000980         25242409             NaN   50882      24.0    mEq/L   \n",
       "4    10000980         25242409             NaN   50902     110.0    mEq/L   \n",
       "\n",
       "       flag           charttime  outcome          index_date  \\\n",
       "0       NaN 2185-09-17 12:10:00    False 2191-04-03 18:48:00   \n",
       "1       NaN 2185-09-17 12:10:00    False 2191-04-03 18:48:00   \n",
       "2       NaN 2185-09-17 12:10:00    False 2191-04-03 18:48:00   \n",
       "3       NaN 2185-09-17 12:10:00    False 2191-04-03 18:48:00   \n",
       "4  abnormal 2185-09-17 12:10:00    False 2191-04-03 18:48:00   \n",
       "\n",
       "                                   label  fluid  \n",
       "0   Blood Alanine Aminotransferase (ALT)  Blood  \n",
       "1                        Blood Anion Gap  Blood  \n",
       "2  Blood Asparate Aminotransferase (AST)  Blood  \n",
       "3                      Blood Bicarbonate  Blood  \n",
       "4                         Blood Chloride  Blood  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_labs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df = fg.current_bloods_df(processed_labs, lead_time=21, n_days_pre=3, n_days_post=1)\n",
    "historical_df = fg.historical_labs(processed_labs, n_days=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df['nulls'] = current_df.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.185840707964602"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*sum(current_df['nulls']==53)/len(current_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>Blood Alanine Aminotransferase (ALT)</th>\n",
       "      <th>Blood Albumin</th>\n",
       "      <th>Blood Alkaline Phosphatase</th>\n",
       "      <th>Blood Anion Gap</th>\n",
       "      <th>Blood Asparate Aminotransferase (AST)</th>\n",
       "      <th>Blood Basophils</th>\n",
       "      <th>Blood Bicarbonate</th>\n",
       "      <th>Blood Bilirubin, Total</th>\n",
       "      <th>Blood Calcium, Total</th>\n",
       "      <th>...</th>\n",
       "      <th>Blood Green Top Hold (plasma)</th>\n",
       "      <th>Urine Bilirubin</th>\n",
       "      <th>Urine Blood</th>\n",
       "      <th>Urine Leukocytes</th>\n",
       "      <th>Urine Nitrite</th>\n",
       "      <th>Urine Urine Appearance</th>\n",
       "      <th>Urine Urine Color</th>\n",
       "      <th>Urine Yeast</th>\n",
       "      <th>outcome</th>\n",
       "      <th>nulls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10006029</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9.80</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10030549</td>\n",
       "      <td>12.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>9.45</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10048244</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>77.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8.95</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10052992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10151324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "label  subject_id  Blood Alanine Aminotransferase (ALT)  Blood Albumin  \\\n",
       "0        10006029                                  24.0            4.0   \n",
       "1        10030549                                  12.5            NaN   \n",
       "2        10048244                                  20.0            3.5   \n",
       "3        10052992                                   NaN            NaN   \n",
       "4        10151324                                   NaN            NaN   \n",
       "\n",
       "label  Blood Alkaline Phosphatase  Blood Anion Gap  \\\n",
       "0                           148.0              9.0   \n",
       "1                           165.5             11.5   \n",
       "2                            77.0             16.0   \n",
       "3                             NaN              NaN   \n",
       "4                             NaN              NaN   \n",
       "\n",
       "label  Blood Asparate Aminotransferase (AST)  Blood Basophils  \\\n",
       "0                                       23.0         0.300000   \n",
       "1                                       13.0         0.333333   \n",
       "2                                       19.0              NaN   \n",
       "3                                        NaN              NaN   \n",
       "4                                        NaN              NaN   \n",
       "\n",
       "label  Blood Bicarbonate  Blood Bilirubin, Total  Blood Calcium, Total  ...  \\\n",
       "0                   23.0                     0.4                  9.80  ...   \n",
       "1                   26.0                     0.2                  9.45  ...   \n",
       "2                   24.0                     0.2                  8.95  ...   \n",
       "3                    NaN                     NaN                   NaN  ...   \n",
       "4                    NaN                     NaN                   NaN  ...   \n",
       "\n",
       "label  Blood Green Top Hold (plasma)  Urine Bilirubin  Urine Blood  \\\n",
       "0                                NaN              NaN          NaN   \n",
       "1                                NaN              NaN          NaN   \n",
       "2                                NaN              NaN          NaN   \n",
       "3                                NaN              NaN          NaN   \n",
       "4                                NaN              NaN          NaN   \n",
       "\n",
       "label  Urine Leukocytes  Urine Nitrite  Urine Urine Appearance  \\\n",
       "0                   NaN            NaN                     NaN   \n",
       "1                   NaN            NaN                     NaN   \n",
       "2                   NaN            NaN                     NaN   \n",
       "3                   NaN            NaN                     NaN   \n",
       "4                   NaN            NaN                     NaN   \n",
       "\n",
       "label  Urine Urine Color  Urine Yeast  outcome  nulls  \n",
       "0                    NaN          NaN      1.0     25  \n",
       "1                    NaN          NaN      0.0     18  \n",
       "2                    NaN          NaN      0.0     29  \n",
       "3                    NaN          NaN      1.0     42  \n",
       "4                    NaN          NaN      1.0     53  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>index_admission</th>\n",
       "      <th>test_admission</th>\n",
       "      <th>itemid</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>valueuom</th>\n",
       "      <th>flag</th>\n",
       "      <th>charttime</th>\n",
       "      <th>outcome</th>\n",
       "      <th>index_date</th>\n",
       "      <th>label</th>\n",
       "      <th>fluid</th>\n",
       "      <th>pseudo_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000980</td>\n",
       "      <td>25242409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50861</td>\n",
       "      <td>31.0</td>\n",
       "      <td>IU/L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2185-09-17 12:10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2191-04-03 18:48:00</td>\n",
       "      <td>Blood Alanine Aminotransferase (ALT)</td>\n",
       "      <td>Blood</td>\n",
       "      <td>2191-03-13 18:48:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000980</td>\n",
       "      <td>25242409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50868</td>\n",
       "      <td>13.0</td>\n",
       "      <td>mEq/L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2185-09-17 12:10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2191-04-03 18:48:00</td>\n",
       "      <td>Blood Anion Gap</td>\n",
       "      <td>Blood</td>\n",
       "      <td>2191-03-13 18:48:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000980</td>\n",
       "      <td>25242409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50878</td>\n",
       "      <td>32.0</td>\n",
       "      <td>IU/L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2185-09-17 12:10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2191-04-03 18:48:00</td>\n",
       "      <td>Blood Asparate Aminotransferase (AST)</td>\n",
       "      <td>Blood</td>\n",
       "      <td>2191-03-13 18:48:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000980</td>\n",
       "      <td>25242409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50882</td>\n",
       "      <td>24.0</td>\n",
       "      <td>mEq/L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2185-09-17 12:10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2191-04-03 18:48:00</td>\n",
       "      <td>Blood Bicarbonate</td>\n",
       "      <td>Blood</td>\n",
       "      <td>2191-03-13 18:48:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000980</td>\n",
       "      <td>25242409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50902</td>\n",
       "      <td>110.0</td>\n",
       "      <td>mEq/L</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>2185-09-17 12:10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2191-04-03 18:48:00</td>\n",
       "      <td>Blood Chloride</td>\n",
       "      <td>Blood</td>\n",
       "      <td>2191-03-13 18:48:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  index_admission  test_admission  itemid  valuenum valueuom  \\\n",
       "0    10000980         25242409             NaN   50861      31.0     IU/L   \n",
       "1    10000980         25242409             NaN   50868      13.0    mEq/L   \n",
       "2    10000980         25242409             NaN   50878      32.0     IU/L   \n",
       "3    10000980         25242409             NaN   50882      24.0    mEq/L   \n",
       "4    10000980         25242409             NaN   50902     110.0    mEq/L   \n",
       "\n",
       "       flag           charttime  outcome          index_date  \\\n",
       "0       NaN 2185-09-17 12:10:00    False 2191-04-03 18:48:00   \n",
       "1       NaN 2185-09-17 12:10:00    False 2191-04-03 18:48:00   \n",
       "2       NaN 2185-09-17 12:10:00    False 2191-04-03 18:48:00   \n",
       "3       NaN 2185-09-17 12:10:00    False 2191-04-03 18:48:00   \n",
       "4  abnormal 2185-09-17 12:10:00    False 2191-04-03 18:48:00   \n",
       "\n",
       "                                   label  fluid        pseudo_index  \n",
       "0   Blood Alanine Aminotransferase (ALT)  Blood 2191-03-13 18:48:00  \n",
       "1                        Blood Anion Gap  Blood 2191-03-13 18:48:00  \n",
       "2  Blood Asparate Aminotransferase (AST)  Blood 2191-03-13 18:48:00  \n",
       "3                      Blood Bicarbonate  Blood 2191-03-13 18:48:00  \n",
       "4                         Blood Chloride  Blood 2191-03-13 18:48:00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ref range missing: Urine Bacteria\n",
      "Ref range missing: Urine Epithelial Cells\n",
      "Ref range missing: Urine Length of Urine Collection\n",
      "Ref range missing: Blood Estimated GFR (MDRD equation)\n",
      "Ref range missing: Blood Green Top Hold (plasma)\n",
      "Ref range missing: Urine Bilirubin\n",
      "Ref range missing: Urine Blood\n",
      "Ref range missing: Urine Leukocytes\n",
      "Ref range missing: Urine Nitrite\n",
      "Ref range missing: Urine Urine Appearance\n",
      "Ref range missing: Urine Urine Color\n",
      "Ref range missing: Urine Yeast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 3148 subject_ids from current_labs and historical_labs\n",
      "Removed 598 positive outcomes from current_labs\n"
     ]
    }
   ],
   "source": [
    "current_df, historical_df, feature_df = fg.generate_features(processed_labs, cohort_ids, current_window_preindex=35, current_window_postindex=-21, historical_window=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m all_na_columns \u001b[38;5;241m=\u001b[39m feature_df\u001b[38;5;241m.\u001b[39mcolumns[feature_df\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m>\u001b[39m\u001b[38;5;28mlen\u001b[39m(feature_df)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.8\u001b[39m]\n\u001b[0;32m      2\u001b[0m feature_df \u001b[38;5;241m=\u001b[39m feature_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mall_na_columns)\n\u001b[0;32m      3\u001b[0m zero_mask \u001b[38;5;241m=\u001b[39m (feature_df \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feature_df' is not defined"
     ]
    }
   ],
   "source": [
    "all_na_columns = feature_df.columns[feature_df.isna().sum()>len(feature_df)*0.8]\n",
    "feature_df = feature_df.drop(columns=all_na_columns)\n",
    "zero_mask = (feature_df == 0.0)\n",
    "#all_zero_columns = feature_df.columns[zero_mask.sum()>len(feature_df)*0.8]\n",
    "#all_zero_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.isna().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feng_y = nas_removed['outcome']\n",
    "feng_X = nas_removed.drop(columns=[\"outcome\",\"subject_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test = train_test_split(feng_X, feng_y, train_size = 0.8)\n",
    "print(f\"Train Length: {len(X_train)}        Train cases: {len(y_train[y_train==1])}    Proportion: {len(y_train[y_train==1])/len(y_train)*100} %\")\n",
    "print(f\"Test Length: {len(X_test)}          Test cases: {len(y_test[y_test==1])}       Proportion: {len(y_test[y_test==1])/len(y_test)*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Scale training #####\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "X_train_scaled = X_train_scaled.set_axis(X_train.columns,axis=1)\n",
    "\n",
    "#### Scale Test using training scaler ####\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test))\n",
    "X_test_scaled.set_axis(X_test.columns,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_boost = {'max_depth': [2,5,15],\n",
    "    'max_features': [20,26,30],\n",
    "    'min_samples_leaf': [10,50],\n",
    "    'min_samples_split': [4,50],\n",
    "    'n_estimators': [200, 500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = GradientBoostingClassifier()\n",
    "\n",
    "gradboost = GridSearchCV(estimator = boost, param_grid = param_grid_boost,\n",
    "                         cv = 5, verbose = 2, scoring='average_precision')\n",
    "gradboost.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradboost.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_preds = gradboost.predict(X_train_scaled)\n",
    "accuracy = sum(gb_preds==y_train)/len(gb_preds)\n",
    "auc = roc_auc_score(y_train, gb_preds)\n",
    "aps = average_precision_score(y_train, gb_preds)\n",
    "f1 = f1_score(y_train, gb_preds)\n",
    "print('Training Accuracy:', accuracy)\n",
    "print('Training AUC:', auc)\n",
    "print('Training Average Precision Score:', aps)\n",
    "print('Training F1 Score:', f1)\n",
    "\n",
    "\n",
    "gb_conf = confusion_matrix(y_train, gb_preds)\n",
    "gb_disp = ConfusionMatrixDisplay(gb_conf)\n",
    "gb_disp.plot()\n",
    "plt.title('Train Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "gb_preds = gradboost.predict(X_test_scaled)\n",
    "accuracy = sum(gb_preds==y_test)/len(gb_preds)\n",
    "auc = roc_auc_score(y_test, gb_preds)\n",
    "aps = average_precision_score(y_test, gb_preds)\n",
    "f1 = f1_score(y_test, gb_preds)\n",
    "#precision = \n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, gb_preds))\n",
    "print('Test Accuracy:', accuracy)\n",
    "print('Test AUC:', auc)\n",
    "print('Test Average Precision Score:', aps)\n",
    "print('Test F1 Score:', f1)\n",
    "\n",
    "\n",
    "gb_conf = confusion_matrix(y_test, gb_preds)\n",
    "gb_disp = ConfusionMatrixDisplay(gb_conf)\n",
    "gb_disp.plot()\n",
    "plt.title('GBDT Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_default_dtype(torch.float32)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import precision_score, average_precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y  = fg.create_array_for_CNN(processed_labs, -4, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(dir+'CNN_input.npy', X)\n",
    "np.save(dir+'CNN_output.npy', y)\n",
    "print(\"files saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpyDataset(Dataset):\n",
    "    def __init__(self, file_path,labels_file_path):\n",
    "        self.data = np.load(file_path)\n",
    "        self.labels = np.load(labels_file_path)\n",
    "        self.dtype = torch.float32\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        # Assuming you have labels for each sample\n",
    "        label = self.labels[idx]# You should adjust this to fetch labels if available\n",
    "        label = torch.tensor([label], dtype=self.dtype)\n",
    "        sample = torch.tensor(sample, dtype=self.dtype)\n",
    "        sample = torch.unsqueeze(sample, dim=0) \n",
    "\n",
    "        return sample, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to the .npy file\n",
    "file_path = dir+'CNN_input.npy'\n",
    "labels_file_path = dir+'CNN_output.npy'\n",
    "# Create a dataset\n",
    "dataset = NpyDataset(file_path, labels_file_path)\n",
    "\n",
    "# Create a DataLoader to load the dataset\n",
    "batch_size = 32\n",
    "shuffle = True  # You can set it to True if you want to shuffle the data\n",
    "num_workers = 0  # Number of subprocesses to use for data loading (0 means the data will be loaded in the main process)\n",
    "#dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "\n",
    "# Split the dataset indices into training and testing sets\n",
    "train_size = int(0.7 * len(dataset))  # 80% for training, adjust ratio as needed\n",
    "test_size = int(0.2 * len(dataset))  # 20% for testing, adjust ratio as needed\n",
    "val_size = len(dataset)-(train_size+test_size)   # 10% of the training data for validation\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size,val_size, test_size])\n",
    "\n",
    "# Create separate DataLoaders for training and testing\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "# Compute the mean and standard deviation of the dataset\n",
    "mean_sum = 0.0\n",
    "std_sum = 0.0\n",
    "total_samples = 0\n",
    "\n",
    "for data, _ in train_dataloader:\n",
    "    total_samples += data.size(0)\n",
    "    mean_sum += data.mean(dim=(0, 1, 3))  # Calculate mean along batch (0), width (2), and height (3) axes\n",
    "    std_sum += torch.std(data, dim=(0, 1, 3))  # Calculate std along batch (0), width (2), and height (3) axes\n",
    "mean = mean_sum / total_samples    \n",
    "std = std_sum / total_samples\n",
    "\n",
    "custom_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert data to PyTorch tensor\n",
    "    #nan,  # Handle NaN values\n",
    "    transforms.Normalize(mean=[mean], std=[std]),  # Normalize data using computed mean and std\n",
    "    \n",
    "])\n",
    "train_dataloader.transform = custom_transform\n",
    "test_dataloader.transform = custom_transform\n",
    "val_dataloader.transform = custom_transform\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = len(dataset)/(2*sum(dataset.labels == 0))\n",
    "w2 = torch.tensor(len(dataset)/(2*sum(dataset.labels == 1)))\n",
    "weights = torch.tensor([w1,w2], dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your CNN\n",
    "cnn = SimpleCNN()\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([w2]), reduction='mean')\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=1e-6, weight_decay=1e-5)\n",
    "num_epochs = 50\n",
    "# Initialize the best validation loss to positive infinity\n",
    "best_val_loss = float('inf')\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "# Assuming your input data is in the form of a PyTorch tensor\n",
    "# Here's how you can train your CNN\n",
    "for epoch in range(num_epochs):\n",
    "    # Create a progress bar\n",
    "    progress_bar = tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    cnn.train()\n",
    "\n",
    "    # Iterate over the dataset\n",
    "    for inputs, labels in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the running loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Update the progress bar with the current loss\n",
    "        progress_bar.set_postfix({'loss': running_loss / len(progress_bar)})\n",
    "    \n",
    "    # Calculate average loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "    training_losses.append(epoch_loss)\n",
    "    # Validation phase\n",
    "    cnn.eval()  # Set model to evaluation mode\n",
    "    running_val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_dataloader:\n",
    "            outputs = cnn(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "    \n",
    "    # Calculate average validation loss for the epoch\n",
    "    epoch_val_loss = running_val_loss / len(val_dataloader)\n",
    "    validation_losses.append(epoch_val_loss)\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        torch.save(cnn.state_dict(), dir+'/model.pth')\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {epoch_loss:.4f}', 'Validation Loss:', epoch_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute evaluation metrics\n",
    "def evaluate_performance(dataloader):\n",
    "    cnn.load_state_dict(torch.load(dir+'/model.pth'))  # Load the best model\n",
    "    cnn.eval()  # Set the model to evaluation mode\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients during evaluation\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = cnn(inputs)\n",
    "            probabilities = torch.sigmoid(outputs)  # Apply sigmoid to get probabilities\n",
    "            predicted = (probabilities > 0.5).int()\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            predicted_labels.extend(predicted.numpy())\n",
    "            true_labels.extend(labels.numpy())\n",
    "\n",
    "    # Compute accuracy\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    # Compute precision and recall\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, conf_matrix\n",
    "\n",
    "# Evaluate performance on training dataset\n",
    "train_accuracy, train_precision, train_recall, train_conf_matrix = evaluate_performance(train_dataloader)\n",
    "\n",
    "# Evaluate performance on test dataset\n",
    "test_accuracy, test_precision, test_recall, test_conf_matrix = evaluate_performance(test_dataloader)\n",
    "\n",
    "print('Training Performance:')\n",
    "print(f'Accuracy: {train_accuracy:.2%}')\n",
    "print(f'Precision: {train_precision:.2f}')\n",
    "print(f'Recall: {train_recall:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(train_conf_matrix)\n",
    "\n",
    "print('\\nTest Performance:')\n",
    "print(f'Accuracy: {test_accuracy:.2%}')\n",
    "print(f'Precision: {test_precision:.2f}')\n",
    "print(f'Recall: {test_recall:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(test_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_losses, label='Training Loss')\n",
    "plt.plot(validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class onedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(onedCNN, self).__init__()\n",
    "        # Define your convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1,3), padding=1)\n",
    "        # (input_size - kernel_size + 2*padding)/stride + 1\n",
    "        # (100 - 3 + 2*1)/1 + 1 = 100\n",
    "        # (54 - 1 +2*1)/1 + 1 = 56\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,3), padding=1)\n",
    "        # 50 - 3 + 2*1)/1 + 1 = 50\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(1,3), padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(1,2), padding=1)\n",
    "        # Define your fully connected layers\n",
    "\n",
    "        self.fc1 = nn.Linear(128* 6 * 6, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)  # Assuming you have 2 classes\n",
    "\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "    def forward(self, x):\n",
    "        # Input x has shape (batch_size, channels, height, width)\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.max_pool2d(x, kernel_size=(1,2), stride=2)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.max_pool2d(x, kernel_size=(1,2), stride=2)\n",
    "      \n",
    "        x = self.conv3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.max_pool2d(x, kernel_size=(1,2), stride=2)\n",
    "       \n",
    "        x = self.conv4(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.max_pool2d(x, kernel_size=(1,2), stride=2)\n",
    "        # Flatten the output for the fully connected layers\n",
    "        x = x.view(x.size(0), -1) # x.size(0) is the batch size\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your CNN\n",
    "cnn = onedCNN()\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=w2,  reduction='mean')\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.00001, weight_decay=1e-5)\n",
    "num_epochs = 100\n",
    "\n",
    "training_losses = []\n",
    "val_losses = []\n",
    "# Assuming your input data is in the form of a PyTorch tensor\n",
    "# Here's how you can train your CNN\n",
    "for epoch in range(num_epochs):\n",
    "    # Create a progress bar\n",
    "    progress_bar = tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Iterate over the dataset\n",
    "    for inputs, labels in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the running loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Update the progress bar with the current loss\n",
    "        progress_bar.set_postfix({'loss': running_loss / len(progress_bar)})\n",
    "    \n",
    "    # Calculate average loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "    training_losses.append(epoch_loss)\n",
    "    # Validation phase\n",
    "    cnn.eval()  # Set model to evaluation mode\n",
    "    running_val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_dataloader:\n",
    "            outputs = cnn(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "    \n",
    "    # Calculate average validation loss for the epoch\n",
    "    epoch_val_loss = running_val_loss / len(val_dataloader)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        torch.save(cnn.state_dict(), dir+'/1d_model.pth')\n",
    "    \n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {epoch_loss:.4f}', 'Validation Loss:', epoch_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to compute evaluation metrics\n",
    "def evaluate_cnn_performance(dataloader):\n",
    "    cnn.load_state_dict(torch.load(dir+'/1d_model.pth'))  # Load the best model\n",
    "    cnn.eval()  # Set the model to evaluation mode\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    all_probabilities = []\n",
    "    with torch.no_grad():  # No need to track gradients during evaluation\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = cnn(inputs)\n",
    "            probabilities = torch.sigmoid(outputs)  # Apply sigmoid to get probabilities\n",
    "            predicted = (probabilities > 0.5).int()\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            predicted_labels.extend(predicted.numpy())\n",
    "            true_labels.extend(labels.numpy())\n",
    "            all_probabilities.extend(probabilities.numpy())\n",
    "\n",
    "    # Compute accuracy\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    # Compute precision and recall\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # calculate false positive rate, true positive rate, and thresholds\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, all_probabilities)\n",
    "    # Calculate AUROC\n",
    "    auroc = roc_auc_score(true_labels, all_probabilities)\n",
    "\n",
    "   \n",
    "    # plot ROC curve\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    #plt.show()\n",
    "\n",
    "    return accuracy, precision, recall, conf_matrix, auroc\n",
    "\n",
    "# Evaluate performance on training dataset\n",
    "train_accuracy, train_precision, train_recall, train_conf_matrix, auroc = evaluate_performance(train_dataloader)\n",
    "\n",
    "# Evaluate performance on test dataset\n",
    "test_accuracy, test_precision, test_recall, test_conf_matrix, auroc = evaluate_performance(test_dataloader)\n",
    "\n",
    "print('Training Performance:')\n",
    "print(f'Accuracy: {train_accuracy:.2%}')\n",
    "print(f'AUROC: {auroc:.2f}')\n",
    "print(f'Precision: {train_precision:.2f}')\n",
    "print(f'Recall: {train_recall:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(train_conf_matrix)\n",
    "\n",
    "print('\\nTest Performance:')\n",
    "print(f'Accuracy: {test_accuracy:.2%}')\n",
    "print(f'AUROC: {auroc:.2f}')\n",
    "print(f'Precision: {test_precision:.2f}')\n",
    "print(f'Recall: {test_recall:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(test_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1d conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape so that each patient has 54 channels of 1d time series data\n",
    "num_patients = X.shape[0]\n",
    "num_tests = X.shape[1]\n",
    "num_timesteps = X.shape[2]\n",
    "reshaped_array = X.reshape(num_patients, num_tests, num_timesteps)\n",
    "\n",
    "reshaped_array = np.transpose(reshaped_array, (0, 2, 1))\n",
    "\n",
    "np.save(dir+'CNN_1d_input.npy', X)\n",
    "np.save(dir+'CNN_1d_output.npy', y)\n",
    "print(\"files saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as before except without the unsqueeze to show 1 channel\n",
    "class OneD_Dataset(Dataset):\n",
    "    def __init__(self, file_path,labels_file_path):\n",
    "        self.data = np.load(file_path)\n",
    "        self.labels = np.load(labels_file_path)\n",
    "        self.dtype = torch.float32\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        # Assuming you have labels for each sample\n",
    "        label = self.labels[idx]# You should adjust this to fetch labels if available\n",
    "        label = torch.tensor([label], dtype=self.dtype)\n",
    "        sample = torch.tensor(sample, dtype=self.dtype)\n",
    "        \n",
    "\n",
    "        return sample, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to the .npy file\n",
    "file_path_1d = dir+'CNN_1d_input.npy'\n",
    "labels_file_path_1d = dir+'CNN_1d_output.npy'\n",
    "# Create a dataset\n",
    "dataset_1d = OneD_Dataset(file_path_1d, labels_file_path_1d)\n",
    "\n",
    "# Create a DataLoader to load the dataset\n",
    "batch_size = 100\n",
    "shuffle = True  # You can set it to True if you want to shuffle the data\n",
    "num_workers = 0  # Number of subprocesses to use for data loading (0 means the data will be loaded in the main process)\n",
    "#dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "\n",
    "# Split the dataset indices into training and testing sets\n",
    "train_size = int(0.7 * len(dataset))  # 80% for training, adjust ratio as needed\n",
    "test_size = int(0.2 * len(dataset))  # 20% for testing, adjust ratio as needed\n",
    "val_size = len(dataset)-(train_size+test_size)   # 10% of the training data for validation\n",
    "train_dataset_1d, val_dataset_1d, test_dataset_1d = torch.utils.data.random_split(dataset_1d, [train_size,val_size, test_size])\n",
    "\n",
    "# Create separate DataLoaders for training and testing\n",
    "train_dataloader_1d = DataLoader(train_dataset_1d, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "test_dataloader_1d = DataLoader(test_dataset_1d, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "val_dataloader_1d = DataLoader(val_dataset_1d, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "# Compute the mean and standard deviation of the dataset\n",
    "mean_sum = 0.0\n",
    "std_sum = 0.0\n",
    "total_samples = 0\n",
    "\n",
    "for data, _ in train_dataloader:\n",
    "    total_samples += data.size(0)\n",
    "    mean_sum += data.mean(dim=(0, 1))  # Calculate mean along batch (0), width (2), and height (3) axes\n",
    "    std_sum += torch.std(data, dim=(0, 1))  # Calculate std along batch (0), width (2), and height (3) axes\n",
    "mean = mean_sum / total_samples    \n",
    "std = std_sum / total_samples\n",
    "\n",
    "custom_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert data to PyTorch tensor\n",
    "    #nan,  # Handle NaN values\n",
    "    transforms.Normalize(mean=[mean], std=[std]),  # Normalize data using computed mean and std\n",
    "    \n",
    "])\n",
    "train_dataloader_1d.transform = custom_transform\n",
    "test_dataloader_1d.transform = custom_transform\n",
    "val_dataloader_1d.transform = custom_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class onedCNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(onedCNN2, self).__init__()\n",
    "        # Define your convolutional layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=54, out_channels=108, kernel_size=3)\n",
    "        # (input_size - kernel_size + 2*padding)/stride + 1\n",
    "        # (100 - 3 + 2*1)/1 + 1 = 100\n",
    "        # (54 - 1 +2*1)/1 + 1 = 56\n",
    "        self.conv2 = nn.Conv1d(in_channels=108, out_channels=216, kernel_size=3, padding=1)\n",
    "        # 50 - 3 + 2*1)/1 + 1 = 50\n",
    "        self.conv3 = nn.Conv1d(in_channels=216, out_channels=216, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(in_channels=216, out_channels=432, kernel_size=2, padding=1)\n",
    "        # Define your fully connected layers\n",
    "\n",
    "        self.fc1 = nn.Linear(432* 7, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)  # Assuming you have 2 classes\n",
    "\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "    def forward(self, x):\n",
    "        # Input x has shape (batch_size, channels, height, width)\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.max_pool1d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.max_pool1d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.max_pool1d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.max_pool1d(x, kernel_size=1, stride=2)\n",
    "        \n",
    "        # Flatten the output for the fully connected layers\n",
    "        x = x.view(x.size(0), -1) # x.size(0) is the batch size\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your CNN\n",
    "cnn = onedCNN2()\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=w2,  reduction='mean')\n",
    "unweighted_criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.00001, weight_decay=1e-5)\n",
    "num_epochs = 100\n",
    "\n",
    "training_losses = []\n",
    "val_losses = []\n",
    "# Assuming your input data is in the form of a PyTorch tensor\n",
    "# Here's how you can train your CNN\n",
    "for epoch in range(num_epochs):\n",
    "    # Create a progress bar\n",
    "    progress_bar = tqdm(train_dataloader_1d, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Iterate over the dataset\n",
    "    for inputs, labels in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the running loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Update the progress bar with the current loss\n",
    "        progress_bar.set_postfix({'loss': running_loss / len(progress_bar)})\n",
    "    \n",
    "    # Calculate average loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_dataloader_1d)\n",
    "    training_losses.append(epoch_loss)\n",
    "    # Validation phase\n",
    "    cnn.eval()  # Set model to evaluation mode\n",
    "    running_val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_dataloader_1d:\n",
    "            outputs = cnn(inputs)\n",
    "            loss = unweighted_criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "    \n",
    "    # Calculate average validation loss for the epoch\n",
    "    epoch_val_loss = running_val_loss / len(val_dataloader_1d)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        torch.save(cnn.state_dict(), dir+'/1d_model.pth')\n",
    "    \n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {epoch_loss:.4f}', 'Validation Loss:', epoch_val_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance on training dataset\n",
    "train_accuracy, train_precision, train_recall, train_conf_matrix, auroc = evaluate_performance(train_dataloader_1d)\n",
    "\n",
    "# Evaluate performance on test dataset\n",
    "test_accuracy, test_precision, test_recall, test_conf_matrix, auroc = evaluate_performance(test_dataloader_1d)\n",
    "\n",
    "print('Training Performance:')\n",
    "print(f'Accuracy: {train_accuracy:.2%}')\n",
    "print(f'AUROC: {auroc:.2f}')\n",
    "print(f'Precision: {train_precision:.2f}')\n",
    "print(f'Recall: {train_recall:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(train_conf_matrix)\n",
    "\n",
    "print('\\nTest Performance:')\n",
    "print(f'Accuracy: {test_accuracy:.2%}')\n",
    "print(f'AUROC: {auroc:.2f}')\n",
    "print(f'Precision: {test_precision:.2f}')\n",
    "print(f'Recall: {test_recall:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(test_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_available = []\n",
    "for i in range(0,X.shape[0]):\n",
    "    times_available.append(sum(sum(X[i,:,:] != 0)!=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_available = np.array(times_available)\n",
    "# Convert labels tensor to a numpy array\n",
    "labels_array = y.to_numpy()\n",
    "\n",
    "# Find the indices of 1s in the labels array\n",
    "indices = np.where(labels_array == True)[0]\n",
    "\n",
    "# Get the corresponding entries in times_available\n",
    "times_available_case = times_available[indices]\n",
    "times_available_control = times_available[np.where(labels_array == False)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot overlapping histograms\n",
    "plt.hist(times_available_case, bins=10, alpha=0.5, label='Case', density=True)\n",
    "plt.hist(times_available_control, bins=10, alpha=0.5, label='Control', density=True)\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Overlapping Histograms of Times Available')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_counts= plt.hist(times_available_case, bins=10, density=True, alpha=0.5)\n",
    "control_counts = plt.hist(times_available_control, bins=10, density=True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_counts, case_bins = np.histogram(times_available_case, bins=10, density=True)\n",
    "control_counts, control_bins = np.histogram(times_available_control, bins=10, density=True)\n",
    "\n",
    "total_observed = sum(case_counts)\n",
    "total_expected = sum(control_counts)\n",
    "\n",
    "case_counts_normalized = [count / total_observed for count in case_counts]\n",
    "control_counts_normalized = [count / total_expected for count in control_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2, pvalue = chisquare(case_counts_normalized, f_exp = control_counts_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributions of the lengths are not significantly different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fg.historical_labs(processed_labs)\n",
    "binned_df = fg.bin_measurements(processed_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(binned_df.loc[10000980].index.levels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN expects input to be of shape [seq_length, batch_size, features] but you can use batch_first=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3609, 54, 100)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_input = X.reshape((3609, 100, 54))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3609, 100, 54)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "np.save(dir+'rnn_input.npy', rnn_input)\n",
    "np.save(dir+'rnn_output.npy', y)\n",
    "print(\"files saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNDataset(Dataset):\n",
    "    def __init__(self, file_path,labels_file_path):\n",
    "        self.data = np.load(file_path)\n",
    "        self.labels = np.load(labels_file_path)\n",
    "        self.dtype = torch.float32\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        # Assuming you have labels for each sample\n",
    "        label = self.labels[idx]# You should adjust this to fetch labels if available\n",
    "        label = torch.tensor([label], dtype=self.dtype)\n",
    "        sample = torch.tensor(sample, dtype=self.dtype)\n",
    "        #sample = torch.unsqueeze(sample, dim=0) \n",
    "\n",
    "        return sample, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to the .npy file\n",
    "file_path = dir+'rnn_input.npy'\n",
    "labels_file_path = dir+'rnn_output.npy'\n",
    "# Create a dataset\n",
    "dataset_rnn = RNNDataset(file_path, labels_file_path)\n",
    "\n",
    "# Create a DataLoader to load the dataset\n",
    "batch_size = 32\n",
    "shuffle = True  # You can set it to True if you want to shuffle the data\n",
    "num_workers = 0  # Number of subprocesses to use for data loading (0 means the data will be loaded in the main process)\n",
    "#dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "\n",
    "# Split the dataset indices into training and testing sets\n",
    "train_size = int(0.7 * len(dataset_rnn))  # 80% for training, adjust ratio as needed\n",
    "test_size = int(0.2 * len(dataset_rnn))  # 20% for testing, adjust ratio as needed\n",
    "val_size = len(dataset_rnn)-(train_size+test_size)   # 10% of the training data for validation\n",
    "train_dataset_rnn, val_dataset_rnn, test_dataset_rnn = torch.utils.data.random_split(dataset_rnn, [train_size,val_size, test_size])\n",
    "\n",
    "# Create separate DataLoaders for training and testing\n",
    "train_dataloader_rnn = DataLoader(train_dataset_rnn, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "test_dataloader_rnn = DataLoader(test_dataset_rnn, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "val_dataloader_rnn = DataLoader(val_dataset_rnn, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "# Compute the mean and standard deviation of the dataset\n",
    "mean_sum = 0.0\n",
    "std_sum = 0.0\n",
    "total_samples = 0\n",
    "\n",
    "for data, _ in train_dataloader_rnn:\n",
    "    total_samples += data.size(0)\n",
    "    mean_sum += data.mean(dim=(0, 1))  # Calculate mean along batch (0), width (2), and height (3) axes\n",
    "    std_sum += torch.std(data, dim=(0, 1))  # Calculate std along batch (0), width (2), and height (3) axes\n",
    "mean = mean_sum / total_samples    \n",
    "std = std_sum / total_samples\n",
    "\n",
    "custom_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert data to PyTorch tensor\n",
    "    #nan,  # Handle NaN values\n",
    "    transforms.Normalize(mean=[mean], std=[std]),  # Normalize data using computed mean and std\n",
    "    \n",
    "])\n",
    "train_dataloader_rnn.transform = custom_transform\n",
    "test_dataloader_rnn.transform = custom_transform\n",
    "val_dataloader_rnn.transform = custom_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhidden = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make LSTM class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MV_LSTM(torch.nn.Module):\n",
    "    def __init__(self,n_features,seq_length):\n",
    "        super(MV_LSTM, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.seq_len = seq_length\n",
    "        self.n_hidden = nhidden # number of hidden states\n",
    "        self.n_layers = 3 # number of LSTM layers (stacked)\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        \n",
    "        self.l_lstm = torch.nn.LSTM(input_size = n_features, \n",
    "                                 hidden_size = self.n_hidden,\n",
    "                                 num_layers = self.n_layers,\n",
    "                                 batch_first=True)\n",
    "        self.l_linear1 = torch.nn.Linear(self.n_hidden*self.seq_len, self.n_hidden*self.seq_len)\n",
    "        self.l_linear2 = torch.nn.Linear(self.n_hidden*self.seq_len, 1)\n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "     \n",
    "    def forward(self, x):        \n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        hidden_state = torch.zeros(self.n_layers,batch_size,self.n_hidden)\n",
    "        cell_state = torch.zeros(self.n_layers,batch_size,self.n_hidden)\n",
    "        hidden = (hidden_state,cell_state)\n",
    "        lstm_out, self.hidden = self.l_lstm(x,hidden)\n",
    "\n",
    "        x = lstm_out.contiguous().view(batch_size,-1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.l_linear1(x)\n",
    "        #self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x=self.l_linear2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 54])\n"
     ]
    }
   ],
   "source": [
    "print(inputs[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/125:   0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/125], Training Loss: 0.8509 Validation Loss: 0.8441815674304962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/125], Training Loss: 0.8436 Validation Loss: 0.8431501140197118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/125], Training Loss: 0.8418 Validation Loss: 0.8516898155212402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/125], Training Loss: 0.8399 Validation Loss: 0.8284816791613897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/125], Training Loss: 0.8352 Validation Loss: 0.8246862143278122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/125], Training Loss: 0.8300 Validation Loss: 0.8269150406122208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/125], Training Loss: 0.8229 Validation Loss: 0.8262323339780172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/125], Training Loss: 0.8156 Validation Loss: 0.8290890206893285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/125], Training Loss: 0.8025 Validation Loss: 0.8092111200094223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/125], Training Loss: 0.7883 Validation Loss: 0.7920638074477514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/125], Training Loss: 0.7727 Validation Loss: 0.7816289166609446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/125], Training Loss: 0.7532 Validation Loss: 0.7695567160844803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/125], Training Loss: 0.7350 Validation Loss: 0.7250758757193884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/125], Training Loss: 0.7131 Validation Loss: 0.7109994093577067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/125], Training Loss: 0.6944 Validation Loss: 0.6840491195519766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/125], Training Loss: 0.6759 Validation Loss: 0.6828573445479075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/125], Training Loss: 0.6578 Validation Loss: 0.6952740997076035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/125], Training Loss: 0.6425 Validation Loss: 0.6522559821605682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/125], Training Loss: 0.6273 Validation Loss: 0.6471487606565157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/125], Training Loss: 0.6175 Validation Loss: 0.6239264259735743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/125], Training Loss: 0.6085 Validation Loss: 0.6254194428523382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/125], Training Loss: 0.5968 Validation Loss: 0.6146898716688156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/125], Training Loss: 0.5868 Validation Loss: 0.6591689685980479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/125], Training Loss: 0.5811 Validation Loss: 0.610549492140611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/125], Training Loss: 0.5741 Validation Loss: 0.6097879409790039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/125], Training Loss: 0.5710 Validation Loss: 0.6033752262592316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/125], Training Loss: 0.5676 Validation Loss: 0.5946441367268562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/125], Training Loss: 0.5625 Validation Loss: 0.6597444862127304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/125], Training Loss: 0.5579 Validation Loss: 0.5938735579450926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/125], Training Loss: 0.5550 Validation Loss: 0.6204157322645187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/125], Training Loss: 0.5481 Validation Loss: 0.596018319328626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/125], Training Loss: 0.5457 Validation Loss: 0.5892728219429652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/125], Training Loss: 0.5464 Validation Loss: 0.5783392029503981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/125], Training Loss: 0.5406 Validation Loss: 0.5750455732146899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/125], Training Loss: 0.5372 Validation Loss: 0.6152286951740583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/125], Training Loss: 0.5330 Validation Loss: 0.578921856979529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/125], Training Loss: 0.5325 Validation Loss: 0.5857106844584147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/125], Training Loss: 0.5302 Validation Loss: 0.585240381459395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/125], Training Loss: 0.5291 Validation Loss: 0.5898028636972109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/125], Training Loss: 0.5267 Validation Loss: 0.583474762737751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/125], Training Loss: 0.5270 Validation Loss: 0.6040461485584577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/125], Training Loss: 0.5227 Validation Loss: 0.5775335679451624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/125], Training Loss: 0.5214 Validation Loss: 0.6013192782799403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/125], Training Loss: 0.5209 Validation Loss: 0.5905635605255762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/125], Training Loss: 0.5183 Validation Loss: 0.5780955428878466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/125], Training Loss: 0.5171 Validation Loss: 0.5867366641759872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/125], Training Loss: 0.5192 Validation Loss: 0.5688371323049068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/125], Training Loss: 0.5154 Validation Loss: 0.6183785224954287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/125], Training Loss: 0.5160 Validation Loss: 0.5727635733783245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/125], Training Loss: 0.5106 Validation Loss: 0.5715805391470591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/125], Training Loss: 0.5084 Validation Loss: 0.5721957137187322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/125], Training Loss: 0.5072 Validation Loss: 0.573520210882028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/125], Training Loss: 0.5062 Validation Loss: 0.5581661102672418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/125], Training Loss: 0.5073 Validation Loss: 0.5622422570983568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/125], Training Loss: 0.5075 Validation Loss: 0.5582485049962997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/125], Training Loss: 0.5026 Validation Loss: 0.5835334286093712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/125], Training Loss: 0.5014 Validation Loss: 0.6302944247921308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/125], Training Loss: 0.5009 Validation Loss: 0.5682098170121511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/125], Training Loss: 0.5009 Validation Loss: 0.5683154712120692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/125], Training Loss: 0.4981 Validation Loss: 0.5858045568068823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/125], Training Loss: 0.4945 Validation Loss: 0.5622703532377878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/125], Training Loss: 0.4935 Validation Loss: 0.5595775494972864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/125], Training Loss: 0.4947 Validation Loss: 0.5838316803177198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/125], Training Loss: 0.4941 Validation Loss: 0.5457447208464146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/125], Training Loss: 0.4900 Validation Loss: 0.5504680027564367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/125], Training Loss: 0.4910 Validation Loss: 0.5766838453710079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/125], Training Loss: 0.4897 Validation Loss: 0.5513972193002701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/125], Training Loss: 0.4874 Validation Loss: 0.5876237601041794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/125], Training Loss: 0.4841 Validation Loss: 0.5619066307942072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/125], Training Loss: 0.4879 Validation Loss: 0.5566956773400307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/125], Training Loss: 0.4835 Validation Loss: 0.5650124053160349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/125], Training Loss: 0.4849 Validation Loss: 0.5528576523065567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/125], Training Loss: 0.4814 Validation Loss: 0.5811683932940165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/125], Training Loss: 0.4806 Validation Loss: 0.5412022483845552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/125], Training Loss: 0.4822 Validation Loss: 0.5537797833482424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/125], Training Loss: 0.4811 Validation Loss: 0.5417587409416834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/125], Training Loss: 0.4788 Validation Loss: 0.583194429675738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/125], Training Loss: 0.4758 Validation Loss: 0.5677648981412252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/125], Training Loss: 0.4740 Validation Loss: 0.5612914909919103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/125], Training Loss: 0.4756 Validation Loss: 0.5382906024654707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/125], Training Loss: 0.4728 Validation Loss: 0.5809916034340858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/125], Training Loss: 0.4734 Validation Loss: 0.580732154349486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/125], Training Loss: 0.4753 Validation Loss: 0.538210696230332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/125], Training Loss: 0.4744 Validation Loss: 0.5405989115436872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/125], Training Loss: 0.4709 Validation Loss: 0.537137138346831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/125], Training Loss: 0.4682 Validation Loss: 0.5430358126759529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/125], Training Loss: 0.4693 Validation Loss: 0.5897509728868803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/125], Training Loss: 0.4686 Validation Loss: 0.5418600092331568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/125], Training Loss: 0.4677 Validation Loss: 0.5286531529078881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/125], Training Loss: 0.4670 Validation Loss: 0.5485799883802732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/125], Training Loss: 0.4665 Validation Loss: 0.5754404775798321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/125], Training Loss: 0.4671 Validation Loss: 0.5706575165192286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/125], Training Loss: 0.4652 Validation Loss: 0.5558697332938513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/125], Training Loss: 0.4610 Validation Loss: 0.5307640718917052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/125], Training Loss: 0.4672 Validation Loss: 0.5350699126720428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/125], Training Loss: 0.4605 Validation Loss: 0.5368195846676826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/125], Training Loss: 0.4578 Validation Loss: 0.53195338199536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/125], Training Loss: 0.4619 Validation Loss: 0.5246577461560568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/125], Training Loss: 0.4569 Validation Loss: 0.5278502739965916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/125], Training Loss: 0.4567 Validation Loss: 0.5638201087713242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [101/125], Training Loss: 0.4566 Validation Loss: 0.5469077453017235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [102/125], Training Loss: 0.4563 Validation Loss: 0.5878840237855911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [103/125], Training Loss: 0.4562 Validation Loss: 0.5312430386741956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [104/125], Training Loss: 0.4578 Validation Loss: 0.5554365416367849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [105/125], Training Loss: 0.4517 Validation Loss: 0.5608867704868317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [106/125], Training Loss: 0.4510 Validation Loss: 0.5569009569784006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [107/125], Training Loss: 0.4498 Validation Loss: 0.5221338843305906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [108/125], Training Loss: 0.4498 Validation Loss: 0.5351741214593252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [109/125], Training Loss: 0.4484 Validation Loss: 0.53326715528965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [110/125], Training Loss: 0.4535 Validation Loss: 0.597544057915608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [111/125], Training Loss: 0.4523 Validation Loss: 0.5427681195239226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [112/125], Training Loss: 0.4485 Validation Loss: 0.5191877596080303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [113/125], Training Loss: 0.4474 Validation Loss: 0.5328784609834353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [114/125], Training Loss: 0.4440 Validation Loss: 0.5375876352190971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [115/125], Training Loss: 0.4475 Validation Loss: 0.5693019876877466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [116/125], Training Loss: 0.4462 Validation Loss: 0.5230531928439935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [117/125], Training Loss: 0.4447 Validation Loss: 0.5716853365302086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [118/125], Training Loss: 0.4444 Validation Loss: 0.5769832345346609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [119/125], Training Loss: 0.4440 Validation Loss: 0.5480175539851189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [120/125], Training Loss: 0.4444 Validation Loss: 0.5217201958100001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [121/125], Training Loss: 0.4438 Validation Loss: 0.5407517962157726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [122/125], Training Loss: 0.4399 Validation Loss: 0.5753039618333181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [123/125], Training Loss: 0.4384 Validation Loss: 0.5122756101191044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [124/125], Training Loss: 0.4403 Validation Loss: 0.568664975464344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [125/125], Training Loss: 0.4373 Validation Loss: 0.5519163881738981\n"
     ]
    }
   ],
   "source": [
    "lstm = MV_LSTM(54, 100)\n",
    "\n",
    "w2 = torch.tensor(len(dataset_rnn)/(2*sum(dataset_rnn.labels == 1)))\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([w2]), reduction='mean')\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "num_epochs = 125\n",
    "\n",
    "# Initialize the best validation loss to positive infinity\n",
    "best_val_loss = float('inf')\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "\n",
    "\n",
    "# Assuming your input data is in the form of a PyTorch tensor\n",
    "# Here's how you can train your CNN\n",
    "for epoch in range(num_epochs):\n",
    "    # Create a progress bar\n",
    "    progress_bar = tqdm(train_dataloader_rnn, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    lstm.train()\n",
    "\n",
    "    # Iterate over the dataset\n",
    "    for inputs, labels in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = lstm(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the running loss\n",
    "        running_loss += loss.item()\n",
    "        # Update the progress bar with the current loss\n",
    "        progress_bar.set_postfix({'loss': running_loss / len(progress_bar)})\n",
    "        \n",
    "    # Calculate average loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_dataloader_rnn)\n",
    "    training_losses.append(epoch_loss)\n",
    "    # Validation phase\n",
    "    lstm.eval()  # Set model to evaluation mode\n",
    "    running_val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_dataloader_rnn:\n",
    "            outputs = lstm(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "    \n",
    "    # Calculate average validation loss for the epoch\n",
    "    epoch_val_loss = running_val_loss / len(val_dataloader_rnn)\n",
    "    validation_losses.append(epoch_val_loss)\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        torch.save(lstm.state_dict(), dir+'/model.pth')\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {epoch_loss:.4f}', 'Validation Loss:', epoch_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b895fd7080>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_losses, label='Training Loss')\n",
    "plt.plot(validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute evaluation metrics\n",
    "def evaluate_performance(model, dataloader):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a recurrent neural network model on a given dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained recurrent neural network model.\n",
    "        dataloader (torch.utils.data.DataLoader): The data loader for the evaluation dataset.\n",
    "\n",
    "    Returns:\n",
    "        accuracy (float): The accuracy of the model on the evaluation dataset.\n",
    "        precision (float): The precision score of the model on the evaluation dataset.\n",
    "        recall (float): The recall score of the model on the evaluation dataset.\n",
    "        conf_matrix (numpy.ndarray): The confusion matrix of the model on the evaluation dataset.\n",
    "        auroc (float): The area under the receiver operating characteristic curve (AUROC) of the model on the evaluation dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    all_probabilities = []\n",
    "    with torch.no_grad():  # No need to track gradients during evaluation\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            probabilities = torch.sigmoid(outputs)  # Apply sigmoid to get probabilities\n",
    "            predicted = (probabilities > 0.5).int()\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            predicted_labels.extend(predicted.numpy())\n",
    "            true_labels.extend(labels.numpy())\n",
    "            all_probabilities.extend(probabilities.numpy())\n",
    "\n",
    "    # Compute accuracy\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    # Compute precision and recall\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # calculate false positive rate, true positive rate, and thresholds\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, all_probabilities)\n",
    "    # Calculate AUROC\n",
    "    auroc = roc_auc_score(true_labels, all_probabilities)\n",
    "\n",
    "   \n",
    "    # plot ROC curve\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    #plt.show()\n",
    "\n",
    "    return accuracy, precision, recall, conf_matrix, auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Performance:\n",
      "Accuracy: 86.41%\n",
      "AUROC: 0.88\n",
      "Precision: 0.73\n",
      "Recall: 0.69\n",
      "Confusion Matrix:\n",
      "[[504  44]\n",
      " [ 54 119]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = lstm # .load_state_dict(dir+'model.pth')\n",
    "accuracy, precision, recall, conf_matrix, auroc =  evaluate_performance(model, test_dataloader_rnn)\n",
    "print('Test Performance:') \n",
    "print(f'Accuracy: {accuracy:.2%}')\n",
    "print(f'AUROC: {auroc:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject_id\n",
      "10000980    False\n",
      "10006029     True\n",
      "10010471    False\n",
      "10014471    False\n",
      "10017764    False\n",
      "            ...  \n",
      "19987216     True\n",
      "19993603    False\n",
      "19994588    False\n",
      "19995320    False\n",
      "19999303    False\n",
      "Name: outcome, Length: 3609, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.3490],\n",
      "        [-7.2825],\n",
      "        [-2.4814],\n",
      "        [ 0.1495],\n",
      "        [-2.0410],\n",
      "        [-2.4579],\n",
      "        [-1.3072],\n",
      "        [-1.4840],\n",
      "        [-2.1964],\n",
      "        [-2.7756]])\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_feng = gradboost.predict(X_test_scaled)\n",
    "probs_feng= gradboost.predict_proba(X_test_scaled)\n",
    "#calculate accuracy of the model\n",
    "accuracy_feng = sum(predictions_feng==y_test)/len(predictions_feng)\n",
    "#calculate AUC of the model\n",
    "auc_feng = roc_auc_score(y_test, predictions_feng)\n",
    "#calculate precision of the model\n",
    "precision_feng = precision_score(y_test, predictions_feng)\n",
    "#calculate recall of the model\n",
    "recall_feng = recall_score(y_test, predictions_feng)\n",
    "#calculate f1 score of the model\n",
    "f1_feng = f1_score(y_test, predictions_feng)\n",
    "#calculate confusion matrix of the model\n",
    "conf_feng = confusion_matrix(y_test, predictions_feng)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_cnn, precision_cnn, recall_cnn, conf_matrix_cnn, auroc_cnn = evaluate_performance(test_dataloader_1d)\n",
    "print('Test Performance:') \n",
    "print(f'Accuracy: {accuracy_cnn:.2%}')\n",
    "print(f'AUROC: {auroc_cnn:.2f}')\n",
    "print(f'Precision: {precision_cnn:.2f}')\n",
    "print(f'Recall: {recall_cnn:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_dict = {'TrendFeatures': accuracy_feng, 'CNN': accuracy_cnn}\n",
    "precision_dict = {'TrendFeatures': precision_feng, 'CNN': precision_cnn}\n",
    "recall_dict = {'TrendFeatures': recall_feng, 'CNN': recall_cnn}\n",
    "f1_dict = {'TrendFeatures': f1_feng, 'CNN': f1_cnn}\n",
    "auc_dict = {'TrendFeatures': auc_feng, 'CNN': auroc_cnn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([precision_dict, recall_dict, f1_dict, auc_dict], index=['Precision', 'Recall', 'F1', 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pivot_table(columns=['Precision', 'Recall', 'F1', 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_correct = 0\n",
    "total_samples = 0\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "all_probabilities = []\n",
    "with torch.no_grad():  # No need to track gradients during evaluation\n",
    "        for inputs, labels in test_dataloader_1d:\n",
    "            outputs = cnn(inputs)\n",
    "            probabilities = torch.sigmoid(outputs)  # Apply sigmoid to get probabilities\n",
    "            predicted = (probabilities > 0.5).int()\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            predicted_labels.extend(predicted.numpy())\n",
    "            true_labels.extend(labels.numpy())\n",
    "            all_probabilities.extend(probabilities.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_cnn = f1_score(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Calculate the FPR and TPR for the GradientBoostingClassifier model\n",
    "fpr_gb, tpr_gb, _ = roc_curve(y_test, probs_feng[:,1])\n",
    "\n",
    "# Calculate the FPR and TPR for the CNN model\n",
    "fpr_cnn, tpr_cnn, _ = roc_curve(true_labels, all_probabilities)\n",
    "\n",
    "# Plot the ROC curves\n",
    "sns.lineplot(x=fpr_gb, y=tpr_gb, label='GradientBoostingClassifier')\n",
    "sns.lineplot(x=fpr_cnn, y=tpr_cnn, label='CNN')\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fis = pd.DataFrame.from_dict({'feature':X_train.columns, 'importances': gradboost.best_estimator_.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(fis, x='feature', y='importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = fis.sort_values(by='importances', ascending=False)\n",
    "ranks['rank'] = range(1, len(ranks)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_features = ranks[ranks['feature'].str.contains('trend')]\n",
    "print(trend_features.sort_values(by='rank', ascending=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradboost.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = current_df.drop(columns=['subject_id','outcome'])\n",
    "new_X.fillna(0, inplace=True)\n",
    "y = current_df['outcome']\n",
    "#split as before\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#scale as before\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  \n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_grad = gradboost.best_estimator_.fit(X_train_scaled, y_train)\n",
    "new_preds = new_grad.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_feng_new = new_grad.predict(X_test_scaled)\n",
    "probs_feng_new= new_grad.predict_proba(X_test_scaled)\n",
    "#calculate accuracy of the model\n",
    "accuracy_feng_new = sum(predictions_feng_new==y_test)/len(predictions_feng_new)\n",
    "#calculate AUC of the model\n",
    "auc_feng_new = roc_auc_score(y_test, predictions_feng_new)\n",
    "#calculate precision of the model\n",
    "precision_feng_new = precision_score(y_test, predictions_feng_new)\n",
    "#calculate recall of the model\n",
    "recall_feng_new = recall_score(y_test, predictions_feng_new)\n",
    "#calculate f1 score of the model\n",
    "f1_feng_new = f1_score(y_test, predictions_feng_new)\n",
    "#calculate confusion matrix of the model\n",
    "conf_feng_new = confusion_matrix(y_test, predictions_feng_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Performance:')     \n",
    "print(f'Accuracy: {accuracy_feng_new:.2%}')\n",
    "print(f'AUROC: {auc_feng_new:.2f}')\n",
    "print(f'Precision: {precision_feng_new:.2f}')\n",
    "print(f'Recall: {recall_feng_new:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_feng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "25*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'max_depth': 15,\n",
    " 'max_features': 20,\n",
    " 'min_samples_leaf': 50,\n",
    " 'min_samples_split': 4,\n",
    " 'n_estimators': 200}\n",
    "model = GradientBoostingClassifier(**best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-sectional Predictions by Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#window parameters\n",
    "window_size = 3\n",
    "window_ends = range(7, 365, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "counter = 0\n",
    "for i in window_ends:\n",
    "    counter +=1\n",
    "    print('Window (',i+window_size,', ', -i,')', '    iteration: ', counter, ' of ', len(window_ends))\n",
    "    current_df = fg.current_bloods_df(processed_labs, i, -i+7)\n",
    "    current_df.fillna(0, inplace=True)\n",
    "    X = current_df.drop(columns=['subject_id','outcome'])\n",
    "    y = current_df['outcome']\n",
    "    window_aucs = []\n",
    "    window_precisions = []\n",
    "    window_recalls = []\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    for j, (train_data, test_data) in enumerate(kf.split(X, y)):\n",
    "\n",
    "        #split as before\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "        X_train = X.iloc[train_data]\n",
    "        X_test = X.iloc[test_data]\n",
    "        y_train = y.iloc[train_data]\n",
    "        y_test = y.iloc[test_data]\n",
    "        \n",
    "        #scale as before\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        #fit as before\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        #predict as before\n",
    "        predictions = model.predict(X_test_scaled)\n",
    "        probabilities = model.predict_proba(X_test_scaled)\n",
    "        #calculate AUC of the model\n",
    "        auc = roc_auc_score(y_test, probabilities[:,1])\n",
    "        #calculate precision of the model\n",
    "        precision = precision_score(y_test, predictions)\n",
    "        #calculate recall of the model\n",
    "        recall = recall_score(y_test, predictions)\n",
    "        window_aucs.append(auc)\n",
    "        window_precisions.append(precision)\n",
    "        window_recalls.append(recall)\n",
    "\n",
    "    aucs.append(sum(window_aucs)/len(window_aucs))\n",
    "    precisions.append(sum(window_precisions)/len(window_precisions))\n",
    "    recalls.append(sum(window_recalls)/len(window_recalls))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-sectional predictions with just test indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_testind = []\n",
    "precisions_testind = []\n",
    "recalls_testind = []\n",
    "counter = 0\n",
    "for i in window_ends:\n",
    "    counter +=1\n",
    "    print('Window (',i+window_size,', ', -i,')', '    iteration: ', counter, ' of ', len(window_ends))\n",
    "    current_df = fg.current_bloods_df(processed_labs, i, -i+7)\n",
    "    current_df.fillna(0, inplace=True)\n",
    "    X = current_df.drop(columns=['subject_id','outcome'])\n",
    "    X[X>0] = 1\n",
    "    y = current_df['outcome']\n",
    "    window_aucs = []\n",
    "    window_precisions = []\n",
    "    window_recalls = []\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    for j, (train_data, test_data) in enumerate(kf.split(X, y)):\n",
    "\n",
    "        #split as before\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "        X_train = X.iloc[train_data]\n",
    "        X_test = X.iloc[test_data]\n",
    "        y_train = y.iloc[train_data]\n",
    "        y_test = y.iloc[test_data]\n",
    "        \n",
    "        #scale as before\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        #fit as before\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        #predict as before\n",
    "        predictions = model.predict(X_test_scaled)\n",
    "        probabilities = model.predict_proba(X_test_scaled)\n",
    "        #calculate AUC of the model\n",
    "        auc = roc_auc_score(y_test, probabilities[:,1])\n",
    "        #calculate precision of the model\n",
    "        precision = precision_score(y_test, predictions)\n",
    "        #calculate recall of the model\n",
    "        recall = recall_score(y_test, predictions)\n",
    "        window_aucs.append(auc)\n",
    "        window_precisions.append(precision)\n",
    "        window_recalls.append(recall)\n",
    "\n",
    "    aucs_testind.append(sum(window_aucs)/len(window_aucs))\n",
    "    precisions_testind.append(sum(window_precisions)/len(window_precisions))\n",
    "    recalls_testind.append(sum(window_recalls)/len(window_recalls))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "#Plot the AUCS against the time windows\n",
    "ax1.plot(window_ends, aucs_testind, label='Indicator Only')\n",
    "ax1.plot(window_ends, aucs, label='With Values')\n",
    "ax1.set_xlabel('Time Window')\n",
    "ax1.set_ylabel('AUC')\n",
    "ax1.set_title('AUC vs Time Window')\n",
    "ax1.legend()\n",
    "\n",
    "#Plot the precisions against the time windows\n",
    "ax2.plot(window_ends, precisions_testind, label='Indicator Only')\n",
    "ax2.plot(window_ends, precisions, label='With Values')\n",
    "ax2.set_xlabel('Time Window')\n",
    "ax2.set_ylabel('Precision')\n",
    "ax2.set_title('Precision vs Time Window')\n",
    "ax2.legend()\n",
    "\n",
    "#Plot the recalls against the time windows\n",
    "ax3.plot(window_ends, recalls_testind, label='Indicator Only')\n",
    "ax3.plot(window_ends, recalls, label='With Values')\n",
    "ax3.set_xlabel('Time Window')\n",
    "ax3.set_ylabel('Recall')\n",
    "ax3.set_title('Recall vs Time Window')\n",
    "ax3.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a 2nd degree polynomial to each of the lines of the graphs above and plot the results\n",
    "import numpy as np\n",
    "from numpy.polynomial.polynomial import Polynomial\n",
    "\n",
    "aucs_poly = Polynomial.fit(window_ends, aucs, 2)\n",
    "precisions_poly = Polynomial.fit(window_ends, precisions, 2)\n",
    "recalls_poly = Polynomial.fit(window_ends, recalls, 2)\n",
    "\n",
    "aucs_testind_poly = Polynomial.fit(window_ends, aucs_testind, 2)\n",
    "precisions_testind_poly = Polynomial.fit(window_ends, precisions_testind, 2)\n",
    "recalls_testind_poly = Polynomial.fit(window_ends, recalls_testind, 2)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "#Plot the AUCS against the time windows\n",
    "ax1.plot(window_ends, aucs_testind, label='Indicator Only')\n",
    "ax1.plot(window_ends, aucs, label='With Values')\n",
    "ax1.plot(window_ends, aucs_poly(window_ends), label='Polynomial Fit')\n",
    "ax1.plot(window_ends, aucs_testind_poly(window_ends), label='Polynomial Fit Indicator Only')\n",
    "ax1.set_xlabel('Time Window')\n",
    "ax1.set_ylabel('AUC')\n",
    "ax1.set_title('AUC vs Time Window')\n",
    "ax1.legend()\n",
    "\n",
    "#Plot the precisions against the time windows\n",
    "ax2.plot(window_ends, precisions_testind, label='Indicator Only')\n",
    "ax2.plot(window_ends, precisions, label='With Values')\n",
    "ax2.plot(window_ends, precisions_poly(window_ends), label='Polynomial Fit')\n",
    "ax2.plot(window_ends, precisions_testind_poly(window_ends), label='Polynomial Fit Indicator Only')\n",
    "ax2.set_xlabel('Time Window')\n",
    "ax2.set_ylabel('Precision')\n",
    "ax2.set_title('Precision vs Time Window')\n",
    "ax2.legend()\n",
    "\n",
    "#Plot the recalls against the time windows\n",
    "ax3.plot(window_ends, recalls_testind, label='Indicator Only')\n",
    "ax3.plot(window_ends, recalls, label='With Values')\n",
    "ax3.plot(window_ends, recalls_poly(window_ends), label='Polynomial Fit')\n",
    "ax3.plot(window_ends, recalls_testind_poly(window_ends), label='Polynomial Fit Indicator Only')\n",
    "ax3.set_xlabel('Time Window')\n",
    "ax3.set_ylabel('Recall')\n",
    "ax3.set_title('Recall vs Time Window')\n",
    "ax3.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test CNN code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.CNN_1d import OneD_Dataset, onedCNN2, train_model, initialise_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = initialise_dataloaders(dir+'CNN_1d_input.npy', dir+'CNN_1d_output.npy', 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = onedCNN2()\n",
    "train_model(model, train_loader, val_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LIVER_PRED",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
